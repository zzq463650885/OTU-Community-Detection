# Graduate 
graduate python files

## Usage
go into *.ipynb files & click run buttons

## Information
language: 	python  
author:	 	zhangzq  
create date:	2021/04/21  

## Experiment results

### myNOCD  Hyperparameters & results

#### nocd -> bio72 features & graphs
| n_clusters | max_epochs | learning_rate | decoder_loss | Z_hist  | modularity | cluster_result_plot | hidden_sizes|  
| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| 8 | 500 | 1e-3 | 0.6252 | bad  | 0.0616 | bad  | [128] fake |



#### nocd -> dpwk features & graphs
| n_clusters | weight_decay | max_epochs | learning_rate | decoder_loss | Z_hist  | modularity | cluster_result_plot | hidden_sizes|  
| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| 8 | 1e-2 | 500 | 1e-3 | 0.6252 | bad  | 0.0616 | bad  | [128] |
| 8 | 1e-2 | 500 | 1e-3 | 0.6131 | bad  | 0.0769 | bad  | [256] |
| 8 | 1e-2 | 500 | 1e-3 | 0.6064 | good | 0.1013 | bad  | [512] |
| 8 | 1e-2 | 500 | 1e-3 | 0.6021 | good | 0.0982 | bad  | [1024] |
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ---------------- |
| 8 | 1e-2 | 125 | 1e-3 | 0.4498 | good | 0.2667 | bad  | [512,1024] |
| 8 | 1e-2 | 250 | 1e-3 | 0.4490 | good | 0.2817 | bad  | [512,1024] |
| 8 | 1e-2 | 500 | 1e-3 | 0.9844 | good | 0.3362 | good | [512,1024] |
| 8 | 1e-2 | 750 | 1e-3 | 1.0269 | good | 0.3086 | just | [512,1024] |
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ---------------- |
| 8 | 1e-2 | 125 | 1e-3 | 0.3723 | good | 0.4585 | just | [512,512,1024] |
| 8 | 1e-2 | 250 | 1e-3 | 0.4508 | wdfl | 0.5470 | wdfl | [512,512,1024] |
| 8 | 1e-2 | 500 | 1e-3 | 0.8898 | wdfl | 0.6334 | just | [512,512,1024] |
| 8 | 1e-2 | 750 | 1e-3 | 0.9727 | bad  | 0.3523 | bad  | [512,512,1024] |
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ---------------- |
| 8 | 1e-2 | 125 | 1e-3 | 0.3117 | good | 0.5858 | good | [512,512,1024,128] | 
| 8 | 1e-2 | 250 | 1e-3 | 0.2744 | good | 0.6623 | good | [512,512,1024,128] | 
| 8 | 1e-2 | 500 | 1e-3 | 0.2900 | btfl | 0.6579 | good | [512,512,1024,128] | 
| 8 | 1e-2 | 750 | 1e-3 | 0.3384 | btfl | 0.6174 | just | [512,512,1024,128] | 
| 8 | 1e-2 | 1000| 1e-3 | 0.3234 | btfl | 0.6673 | btfl | [512,512,1024,128] | 
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ---------------- |
| 7 | 1e-2 | 125 | 1e-3 | 0.3131 | good | 0.5998 | just | [512,512,1024,128] | 
| 7 | 1e-2 | 250 | 1e-3 | 0.2696 | btfl | 0.6749 | btfl | [512,512,1024,128] | 
| 7 | 1e-2 | 375 | 1e-3 | 0.3203 | btfl | 0.6074 | btfl | [512,512,1024,128] | 
| 7 | 1e-2 | 500 | 1e-3 | 0.2609 | btfl | 0.6988 | btfl | [512,512,1024,128] | 
| 7 | 1e-2 | 625 | 1e-3 | 0.2738 | btfl | 0.6172 | btfl | [512,512,1024,128] | 
| 7 | 1e-2 | 750 | 1e-3 | 0.3258 | btfl | 0.6662 | btfl | [512,512,1024,128] | 
| 7 | 1e-2 | 750 | 1e-3 | 0.2552 | btfl | 0.7115 | btfl | [512,512,1024,128] | 
| 7 | 1e-2 | 875 | 1e-3 | 0.2777 | btfl | 0.7174 | btfl | [512,512,1024,128] | 
| 7 | 1e-2 | 1000| 1e-3 | 0.2673 | btfl | 0.7397 | btfl | [512,512,1024,128] |
| 7 | 1e-2 | 1125| 1e-3 | 0.2733 | btfl | 0.7182 | btfl | [512,512,1024,128] TODO | 
| 7 | 1e-2 | 1250| 1e-3 | 0.2673 | btfl | 0.7397 | btfl | [512,512,1024,128] | 
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | ---------------- |
| 7 | 1e-2 | 1000| 1e-4 | 0.2673 | btfl | 0.7397 | btfl | [512,512,1024,128] | 
| 7 | 1e-3 | 1000| 1e-3 | 0.4064 | btfl | 0.5653 | bad  | [512,512,1024,128] | 
| 6 | 1e-2 | 1000| 1e-3 | 0.2673 | btfl | 0.7397 | btfl | [512,512,1024,128] | 
| 8 | 1e-2 | 1000| 1e-3 | 0.2673 | btfl | 0.7397 | btfl | [256,512,1024,512,256] | 





