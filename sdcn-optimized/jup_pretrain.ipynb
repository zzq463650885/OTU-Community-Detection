{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adjacent-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.cluster import KMeans\n",
    "# from evaluation import eva\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "purple-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "class AE(nn.Module):\n",
    "\n",
    "    # initially n_input,500,500,2000,10,2000,500,500,n_input\n",
    "    def __init__(self, n_input, n_1, n_2, n_3, n_z, n_d3, n_d2, n_d1 ):\n",
    "        super(AE, self).__init__()\n",
    "        self.enc_1 = Linear(n_input, n_1)\n",
    "        self.enc_2 = Linear(n_1, n_2)\n",
    "        self.enc_3 = Linear(n_2, n_3)\n",
    "        self.z_layer = Linear(n_3, n_z)\n",
    "\n",
    "        self.dec_3 = Linear(n_z, n_d3)\n",
    "        self.dec_2 = Linear(n_d3, n_d2)\n",
    "        self.dec_1 = Linear(n_d2, n_d1)\n",
    "        self.x_bar_layer = Linear(n_d1, n_input)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc_h1 = F.relu(self.enc_1(x))\n",
    "        enc_h2 = F.relu(self.enc_2(enc_h1))\n",
    "        enc_h3 = F.relu(self.enc_3(enc_h2))\n",
    "        z = self.z_layer(enc_h3)\n",
    "\n",
    "        dec_h3 = F.relu(self.dec_3(z))\n",
    "        dec_h2 = F.relu(self.dec_2(dec_h3))\n",
    "        dec_h1 = F.relu(self.dec_1(dec_h2))\n",
    "        x_bar = self.x_bar_layer(dec_h1)\n",
    "\n",
    "        return x_bar, z\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x = data\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(np.array(self.x[idx])).float(), \\\n",
    "               torch.from_numpy(np.array(idx))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = 0.001 * (0.1 ** (epoch // 20))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "industrial-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pretrain_ae(model, dataset, y):\n",
    "def pretrain_ae(epochs, model, dataset, out_fname, _lr ):\n",
    "    train_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "    print(model)\n",
    "    optimizer = Adam(model.parameters(), lr=_lr )   # lr\n",
    "    for epoch in range( epochs ):\n",
    "        # adjust_learning_rate(optimizer, epoch)\n",
    "        for batch_idx, (x, _) in enumerate(train_loader):\n",
    "            x = x.cuda()\n",
    "\n",
    "            x_bar, _ = model(x)\n",
    "            loss = F.mse_loss(x_bar, x)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.Tensor(dataset.x).cuda().float()\n",
    "            x_bar, z = model(x)\n",
    "            loss = F.mse_loss(x_bar, x)\n",
    "            print('{} loss: {}'.format(epoch, loss))           \n",
    "        \n",
    "        if epoch == epochs-1:\n",
    "            print('writing...')\n",
    "            torch.save(model.state_dict(), out_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sufficient-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  dopretrain( name, epochs, _n_1, _n_2, _n_3, _n_z, _n_d3, _n_d2, _n_d1, _lr = 1e-3):\n",
    "    print('begin time:{}'.format(time.asctime(time.localtime(time.time()))))    # time \n",
    "\n",
    "    # x = np.loadtxt('dblp.txt', dtype=float)                     # dblp\n",
    "    # y = np.loadtxt('dblp_label.txt', dtype=int)\n",
    "\n",
    "#     in_fname = './mydata/bio72.csv'\n",
    "#     df = pd.read_csv(in_fname, header= 0, index_col= 0)         # bio72\n",
    "#     x = np.array(df).tolist()\n",
    "\n",
    "    in_fname = './mydata/ordered_'+ name + '.txt'\n",
    "    out_fname = './pretrain/' + name + '.pkl'\n",
    "    \n",
    "    print( '{} reading...'.format(in_fname) )\n",
    "    x = np.loadtxt( in_fname, dtype=float)\n",
    "    _n_input = len(x[0])\n",
    "    dataset = LoadDataset(x)\n",
    "    model = AE( \n",
    "        n_input = _n_input, n_1=_n_1,  n_2=_n_2,  n_3=_n_3,\n",
    "        n_z = _n_z,  n_d3=_n_d3,  n_d2=_n_d2, n_d1=_n_d1 ).cuda()\n",
    "    \n",
    "    print( 'pretraining...' )\n",
    "    pretrain_ae(epochs, model, dataset, out_fname, _lr)\n",
    "    print('end time:{}'.format(time.asctime(time.localtime(time.time()))))    # time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hispanic-holmes",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin time:Fri Apr 16 13:44:11 2021\n",
      "./mydata/ordered_dpwk.txt reading...\n",
      "pretraining...\n",
      "AE(\n",
      "  (enc_1): Linear(in_features=128, out_features=500, bias=True)\n",
      "  (enc_2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (enc_3): Linear(in_features=500, out_features=2000, bias=True)\n",
      "  (z_layer): Linear(in_features=2000, out_features=10, bias=True)\n",
      "  (dec_3): Linear(in_features=10, out_features=2000, bias=True)\n",
      "  (dec_2): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (dec_1): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (x_bar_layer): Linear(in_features=500, out_features=128, bias=True)\n",
      ")\n",
      "0 loss: 0.08386076986789703\n",
      "1 loss: 0.06812795996665955\n",
      "2 loss: 0.06061800196766853\n",
      "3 loss: 0.05757823958992958\n",
      "4 loss: 0.05536290258169174\n",
      "5 loss: 0.053814295679330826\n",
      "6 loss: 0.052566058933734894\n",
      "7 loss: 0.05150995030999184\n",
      "8 loss: 0.050626110285520554\n",
      "9 loss: 0.04965493828058243\n",
      "10 loss: 0.04909583181142807\n",
      "11 loss: 0.04842080548405647\n",
      "12 loss: 0.048101361840963364\n",
      "13 loss: 0.04755966365337372\n",
      "14 loss: 0.04703567177057266\n",
      "15 loss: 0.046613045036792755\n",
      "16 loss: 0.046311065554618835\n",
      "17 loss: 0.04593530669808388\n",
      "18 loss: 0.04562457650899887\n",
      "19 loss: 0.04526562988758087\n",
      "20 loss: 0.045043911784887314\n",
      "21 loss: 0.044726379215717316\n",
      "22 loss: 0.04453686624765396\n",
      "23 loss: 0.04421583563089371\n",
      "24 loss: 0.04412003606557846\n",
      "25 loss: 0.04372676461935043\n",
      "26 loss: 0.043578844517469406\n",
      "27 loss: 0.043347492814064026\n",
      "28 loss: 0.043212227523326874\n",
      "29 loss: 0.042825229465961456\n",
      "30 loss: 0.04276566579937935\n",
      "31 loss: 0.04261229187250137\n",
      "32 loss: 0.042427293956279755\n",
      "33 loss: 0.042243607342243195\n",
      "34 loss: 0.04219832643866539\n",
      "35 loss: 0.042083777487277985\n",
      "36 loss: 0.04177949205040932\n",
      "37 loss: 0.041827693581581116\n",
      "38 loss: 0.041659045964479446\n",
      "39 loss: 0.04136219248175621\n",
      "40 loss: 0.041289880871772766\n",
      "41 loss: 0.041246380656957626\n",
      "42 loss: 0.041096560657024384\n",
      "43 loss: 0.040903449058532715\n",
      "44 loss: 0.040688928216695786\n",
      "45 loss: 0.04084176942706108\n",
      "46 loss: 0.040611132979393005\n",
      "47 loss: 0.04054482281208038\n",
      "48 loss: 0.04030151292681694\n",
      "49 loss: 0.04040125384926796\n",
      "writing...\n",
      "end time:Fri Apr 16 13:45:04 2021\n",
      "begin time:Fri Apr 16 13:45:04 2021\n",
      "./mydata/ordered_line.txt reading...\n",
      "pretraining...\n",
      "AE(\n",
      "  (enc_1): Linear(in_features=128, out_features=500, bias=True)\n",
      "  (enc_2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (enc_3): Linear(in_features=500, out_features=2000, bias=True)\n",
      "  (z_layer): Linear(in_features=2000, out_features=10, bias=True)\n",
      "  (dec_3): Linear(in_features=10, out_features=2000, bias=True)\n",
      "  (dec_2): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (dec_1): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (x_bar_layer): Linear(in_features=500, out_features=128, bias=True)\n",
      ")\n",
      "0 loss: 0.08330952376127243\n",
      "1 loss: 0.05736633390188217\n",
      "2 loss: 0.044943466782569885\n",
      "3 loss: 0.03885059058666229\n",
      "4 loss: 0.03575696051120758\n",
      "5 loss: 0.03358280658721924\n",
      "6 loss: 0.03236809000372887\n",
      "7 loss: 0.031154589727520943\n",
      "8 loss: 0.030382933095097542\n",
      "9 loss: 0.029489530250430107\n",
      "10 loss: 0.028861606493592262\n",
      "11 loss: 0.02818134054541588\n",
      "12 loss: 0.027830367907881737\n",
      "13 loss: 0.027164965867996216\n",
      "14 loss: 0.026854224503040314\n",
      "15 loss: 0.026485813781619072\n",
      "16 loss: 0.026357075199484825\n",
      "17 loss: 0.025700418278574944\n",
      "18 loss: 0.02563445270061493\n",
      "19 loss: 0.025355294346809387\n",
      "20 loss: 0.024996107444167137\n",
      "21 loss: 0.024880308657884598\n",
      "22 loss: 0.024512087926268578\n",
      "23 loss: 0.024426257237792015\n",
      "24 loss: 0.024224957451224327\n",
      "25 loss: 0.02408760040998459\n",
      "26 loss: 0.023835882544517517\n",
      "27 loss: 0.023725369945168495\n",
      "28 loss: 0.023644564673304558\n",
      "29 loss: 0.02340499497950077\n",
      "30 loss: 0.023312989622354507\n",
      "31 loss: 0.023062689229846\n",
      "32 loss: 0.022923363372683525\n",
      "33 loss: 0.02287277951836586\n",
      "34 loss: 0.022746674716472626\n",
      "35 loss: 0.022657524794340134\n",
      "36 loss: 0.022508936002850533\n",
      "37 loss: 0.02236315794289112\n",
      "38 loss: 0.022444505244493484\n",
      "39 loss: 0.022057509049773216\n",
      "40 loss: 0.022049430757761\n",
      "41 loss: 0.02200464904308319\n",
      "42 loss: 0.021877899765968323\n",
      "43 loss: 0.02184176631271839\n",
      "44 loss: 0.021676398813724518\n",
      "45 loss: 0.021658848971128464\n",
      "46 loss: 0.021526342257857323\n",
      "47 loss: 0.0214503463357687\n",
      "48 loss: 0.021468207240104675\n",
      "49 loss: 0.02123337984085083\n",
      "writing...\n",
      "end time:Fri Apr 16 13:45:55 2021\n",
      "begin time:Fri Apr 16 13:45:55 2021\n",
      "./mydata/ordered_lle.txt reading...\n",
      "pretraining...\n",
      "AE(\n",
      "  (enc_1): Linear(in_features=128, out_features=500, bias=True)\n",
      "  (enc_2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (enc_3): Linear(in_features=500, out_features=2000, bias=True)\n",
      "  (z_layer): Linear(in_features=2000, out_features=10, bias=True)\n",
      "  (dec_3): Linear(in_features=10, out_features=2000, bias=True)\n",
      "  (dec_2): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (dec_1): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (x_bar_layer): Linear(in_features=500, out_features=128, bias=True)\n",
      ")\n",
      "0 loss: 4.0216757042799145e-05\n",
      "1 loss: 4.047255060868338e-05\n",
      "2 loss: 4.0374881791649386e-05\n",
      "3 loss: 4.0358911064686254e-05\n",
      "4 loss: 4.0638162317918614e-05\n",
      "5 loss: 4.0011684177443385e-05\n",
      "6 loss: 3.994461440015584e-05\n",
      "7 loss: 4.001665729447268e-05\n",
      "8 loss: 3.994046710431576e-05\n",
      "9 loss: 3.994306462118402e-05\n",
      "10 loss: 4.0099799662129954e-05\n",
      "11 loss: 3.990910772699863e-05\n",
      "12 loss: 3.9589380321558565e-05\n",
      "13 loss: 3.946981451008469e-05\n",
      "14 loss: 3.940917304134928e-05\n",
      "15 loss: 3.9191931136883795e-05\n",
      "16 loss: 3.9015605580061674e-05\n",
      "17 loss: 3.894855035468936e-05\n",
      "18 loss: 3.854979149764404e-05\n",
      "19 loss: 3.786613160627894e-05\n",
      "20 loss: 3.7111421988811344e-05\n",
      "21 loss: 3.611773354350589e-05\n",
      "22 loss: 3.515420758049004e-05\n",
      "23 loss: 3.384597584954463e-05\n",
      "24 loss: 3.253239265177399e-05\n",
      "25 loss: 3.1791878427611664e-05\n",
      "26 loss: 3.0241166314226575e-05\n",
      "27 loss: 2.9486671337508596e-05\n",
      "28 loss: 2.8137912522652186e-05\n",
      "29 loss: 2.6870544388657436e-05\n",
      "30 loss: 2.5960443963413127e-05\n",
      "31 loss: 2.5596687919460237e-05\n",
      "32 loss: 2.4095630578813143e-05\n",
      "33 loss: 2.2884081772645004e-05\n",
      "34 loss: 2.1753334294771776e-05\n",
      "35 loss: 2.129901258740574e-05\n",
      "36 loss: 2.039026549027767e-05\n",
      "37 loss: 1.9634273485280573e-05\n",
      "38 loss: 1.900793176901061e-05\n",
      "39 loss: 1.8342325347475708e-05\n",
      "40 loss: 1.7774505977286026e-05\n",
      "41 loss: 1.7078438759199344e-05\n",
      "42 loss: 1.6626989236101508e-05\n",
      "43 loss: 1.692742807790637e-05\n",
      "44 loss: 1.58503171405755e-05\n",
      "45 loss: 1.612083906366024e-05\n",
      "46 loss: 1.5249643183778971e-05\n",
      "47 loss: 1.465343029849464e-05\n",
      "48 loss: 1.4852950698696077e-05\n",
      "49 loss: 1.3980659787193872e-05\n",
      "writing...\n",
      "end time:Fri Apr 16 13:46:45 2021\n",
      "begin time:Fri Apr 16 13:46:45 2021\n",
      "./mydata/ordered_n2v.txt reading...\n",
      "pretraining...\n",
      "AE(\n",
      "  (enc_1): Linear(in_features=128, out_features=500, bias=True)\n",
      "  (enc_2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (enc_3): Linear(in_features=500, out_features=2000, bias=True)\n",
      "  (z_layer): Linear(in_features=2000, out_features=10, bias=True)\n",
      "  (dec_3): Linear(in_features=10, out_features=2000, bias=True)\n",
      "  (dec_2): Linear(in_features=2000, out_features=500, bias=True)\n",
      "  (dec_1): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (x_bar_layer): Linear(in_features=500, out_features=128, bias=True)\n",
      ")\n",
      "0 loss: 0.022007253021001816\n",
      "1 loss: 0.015935653820633888\n",
      "2 loss: 0.012829589657485485\n",
      "3 loss: 0.011704794131219387\n",
      "4 loss: 0.010899154469370842\n",
      "5 loss: 0.010426964610815048\n",
      "6 loss: 0.009893219918012619\n",
      "7 loss: 0.009592540562152863\n",
      "8 loss: 0.009179675951600075\n",
      "9 loss: 0.008933434262871742\n",
      "10 loss: 0.008674840442836285\n",
      "11 loss: 0.00836622528731823\n",
      "12 loss: 0.00823801290243864\n",
      "13 loss: 0.007908075116574764\n",
      "14 loss: 0.007924835197627544\n",
      "15 loss: 0.007730545476078987\n",
      "16 loss: 0.0075834826566278934\n",
      "17 loss: 0.00751556595787406\n",
      "18 loss: 0.007451528217643499\n",
      "19 loss: 0.007284872699528933\n",
      "20 loss: 0.0071541909128427505\n",
      "21 loss: 0.007080629467964172\n",
      "22 loss: 0.00698572862893343\n",
      "23 loss: 0.006965148262679577\n",
      "24 loss: 0.00679960660636425\n",
      "25 loss: 0.006822290830314159\n",
      "26 loss: 0.00664362171664834\n",
      "27 loss: 0.0066303592175245285\n",
      "28 loss: 0.006530596408993006\n",
      "29 loss: 0.00653524324297905\n",
      "30 loss: 0.0064900778234004974\n",
      "31 loss: 0.006482900585979223\n",
      "32 loss: 0.006310580763965845\n",
      "33 loss: 0.006309022195637226\n",
      "34 loss: 0.0063133505173027515\n",
      "35 loss: 0.006214780267328024\n",
      "36 loss: 0.006183850113302469\n",
      "37 loss: 0.006060886196792126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 loss: 0.006099383812397718\n",
      "39 loss: 0.006061929278075695\n",
      "40 loss: 0.006003014277666807\n",
      "41 loss: 0.0059440829791128635\n",
      "42 loss: 0.005954446271061897\n",
      "43 loss: 0.005918282084167004\n",
      "44 loss: 0.005827981512993574\n",
      "45 loss: 0.005762611981481314\n",
      "46 loss: 0.00575792184099555\n",
      "47 loss: 0.00572360772639513\n",
      "48 loss: 0.005682235583662987\n",
      "49 loss: 0.005712111946195364\n",
      "writing...\n",
      "end time:Fri Apr 16 13:47:36 2021\n"
     ]
    }
   ],
   "source": [
    "# do pretrain for embeddings\n",
    "names = ['dpwk','line','lle','n2v']\n",
    "for name in names:\n",
    "    dopretrain(name,50, 500,500,2000,10,2000,500,500, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-wagon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
